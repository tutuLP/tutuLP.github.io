决策树

~~~
!ls /home/aistudio/data
!ls /home/aistudio
!mkdir /home/aistudio/external-libraries
!pip install beautifulsoup4 -t /home/aistudio/external-libraries
import sys 
sys.path.append('/home/aistudio/external-libraries')

#加载库和文件
import pandas as pd  
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import f1_score

# 读取数据
train_data = pd.read_csv('train_set.csv')
test_data = pd.read_csv('test_set.csv')

# 删除缺失值
train_data.dropna(inplace=True)
test_data.dropna(inplace=True)

# 编码非数值特征
label_encoders = {}
for column in train_data.select_dtypes(include=['object']).columns:
    if column != 'is_fraud':
        le = LabelEncoder()
        # 在合并数据上拟合编码器以确保一致性
        combined_data = pd.concat([train_data[column], test_data[column]], axis=0)
        le.fit(combined_data)
        train_data[column] = le.transform(train_data[column])
        test_data[column] = le.transform(test_data[column])
        label_encoders[column] = le
        
# 特征工程：选择相关特征
features = train_data.drop('is_fraud', axis=1).columns
X = train_data[features]
y = train_data['is_fraud']

# 划分训练集和验证集
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

# 训练模型
model = RandomForestClassifier(random_state=42)
model.fit(X_train, y_train)

# 预测验证集
y_pred = model.predict(X_val)

# 计算F1值
f1 = f1_score(y_val, y_pred)
print(f'F1 Score: {f1}')

# 预测测试集
# 确保特征顺序一致
test_features = test_data[features]

# 预测测试集
test_predictions = model.predict(test_features)

# 生成结果文件
output = pd.DataFrame({'Index': test_data['index'], 'is_fraud': test_predictions})
output.to_csv('202231060621.csv', index=False)

F1 Score: 0.7398843930635838
~~~





~~~py
# 加载库
import pandas as pd
from sklearn.preprocessing import OrdinalEncoder, StandardScaler
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import f1_score

# 读取数据
train_data = pd.read_csv('train_set.csv')
test_data = pd.read_csv('test_set.csv')

# 删除缺失值
train_data.dropna(inplace=True)
test_data.dropna(inplace=True)

# 编码非数值特征
ordinal_encoders = {}
categorical_cols = train_data.select_dtypes(include=['object']).columns.drop('is_fraud')

for column in categorical_cols:
    oe = OrdinalEncoder()
    combined_data = pd.concat([train_data[[column]], test_data[[column]]], axis=0)
    oe.fit(combined_data)
    train_data[column] = oe.transform(train_data[[column]])
    test_data[column] = oe.transform(test_data[[column]])
    ordinal_encoders[column] = oe

# 特征工程：选择相关特征
features = train_data.drop('is_fraud', axis=1).columns
X = train_data[features]
y = train_data['is_fraud']

# 特征缩放
scaler = StandardScaler()
X = scaler.fit_transform(X)
test_data_scaled = scaler.transform(test_data[features])

# 划分训练集和验证集
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

# 使用网格搜索调整超参数
param_grid = {
    'C': [0.01, 0.1, 1, 10, 100],
    'solver': ['liblinear', 'saga']
}

grid_search = GridSearchCV(LogisticRegression(random_state=42), param_grid, scoring='f1', cv=5)
grid_search.fit(X_train, y_train)

# 输出最佳参数
print(f'Best Parameters: {grid_search.best_params_}')

# 使用最佳参数训练模型
best_model = grid_search.best_estimator_
best_model.fit(X_train, y_train)

# 预测验证集
y_pred = best_model.predict(X_val)

# 计算F1值
f1 = f1_score(y_val, y_pred)
print(f'F1 Score: {f1}')

# 预测测试集
test_predictions = best_model.predict(test_data_scaled)

# 生成结果文件
output = pd.DataFrame({'Index': test_data['index'], 'is_fraud': test_predictions})
output.to_csv('202231060621.csv', index=False)

~~~



~~~py
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.model_selection import GridSearchCV, cross_val_score

# 使用Gradient Boosting
gb_model = GradientBoostingClassifier(random_state=42)

# 网格搜索优化超参数
param_grid = {
    'n_estimators': [100, 200],
    'max_depth': [3, 5],
    'learning_rate': [0.01, 0.1]
}

grid_search = GridSearchCV(gb_model, param_grid, cv=5, scoring='f1')
grid_search.fit(X_train, y_train)

# 使用最佳参数训练模型
best_model = grid_search.best_estimator_
best_model.fit(X_train, y_train)

# 验证集预测
y_pred = best_model.predict(X_val)

# 计算F1值
f1 = f1_score(y_val, y_pred)
print(f'Optimized F1 Score: {f1}')

# 测试集预测
test_predictions = best_model.predict(test_features)

# 生成结果文件
output = pd.DataFrame({'Index': test_data['index'], 'is_fraud': test_predictions})
output.to_csv('optimized_results.csv', index=False)

~~~

