# rust编码规范

## 时间使用

* 获取当前时间

`use stock_tool_box::trade_date_util::get_local_now;`

`let time = get_local_now().format("%Y-%m-%d %H:%M:%S").to_string();`

> 不能使用chrono::local::now,有性能问题

* 时间戳的使用要用纳秒，获取方式

获取纳秒`SystemTime::now().duration_since(UNIX_EPOCH).unwrap().as_nanos() as i64`
获取毫秒`SystemTime::now().duration_since(UNIX_EPOCH).unwrap().as_millis() as i64`

## 基础规范

非必要不使用异步代码。

减少不必要的clone，每次clone都是一个内存拷贝，大量的clone影响性能。

减少网络io磁盘io等同步操作，读写redis、kafka等都要channel异步.

O(n)的时间复杂度要想一下可否到O(1)，O(N^2)的时间复杂度要设计为O(N)或者O(N * logN)

不要用json用capnp，同时尽可能减少代码之中的String。

## 注释与校验

必要的可能出错函数或逻辑需要使用单测进行验证。

所有函数方法都需要添加注释。

代码中的sleep()方法都要注释说明sleep的时长不会导致性能问题。

## 错误处理

* 规避unwrap，规避let _ =, 规避unwarp_or，规避expect

unwrap要慎用，大部分unwrap都要用if else的错误处理代码来代替。
必要的unwrap代码都必须加上注释解释，要么是故意允许panic，写清楚什么情况下会panic，要么是注释说明不会触发panic。
expect只是让报错信息更丰富，并不能规避panic。
有代码会用let _ =来跳过错误处理，这种写法会完全不处理错误，也要规避。
unwarp_or也是一个不太友好的用法，在不知道下游会如何使用是擅自指定一个默认值可能会导致异常逻辑，出现问题也不好排查。

* 慎重返回默认值

返回默认值可能会引起下游异常，如果使用默认值要明确标注什么情况使用且不会影响下游，不确定就返回anyhow::Err或者Option。

* 规避除0

浮点数除0会出现inf或者-inf，造成下游异常。整数除0会panic，造成线程崩溃。所有的除法都要注释解释是否可能有除0的情况。如果可能除零，那么要加上if-else判断，如果不可能除零，那么要注释标注不可能除零。

* 校验代码

读取网络协议要校验版本，校验上游发过来的每个字段，因为上游代码可能出错。

* 尽量不使用 let Some()  和 let Ok()

容易忘记处理错误分支，如果是明确可以使用比如迭代器`while let Some(x) = iter.next()`需要注释说明失败无语义

## 基础库使用

* ftlog

所有日志输出必须使用异步的log库，error日志打印内容都必须加上panic关键字，如果不加的话需要有注释说明，并且需要有频率限制，避免短时间打印大量错误日志。

* stock-tool-box

判断交易日，获取交易日，获取时间戳等需要使用stock-tool-box中的相关方法

* anyhow

使用anyhow进行错误管理。

* xfloat

浮点数库。

* ordered-float 	

做BtreeMap key的float

* capnp

高性能序列化协议

* fastrand

高性能随机数

* arc-swap

无锁交换Arc

* xcoinai-dict 

基础的String->i16的字典库，可以极大节省资源

* zstd 

综合优秀的压缩算法，支持并行压缩。注意压缩的时候要用auto_finish
`let mut writer = zstd::stream::Encoder::new(writer_file_fd, 3)?;`
`writer.multithread(3)?;`
`let mut writer = writer.auto_finish();`
注意写入的时候要调用writer.write_all()，不要用write.write()，否则会写入不全

## 多线程与高并发

* std::thread 在长生命周期，比如无限循环中使用
* rayon 数据层并发
* 自定义线程池：多任务并发

避免使用tokio等异步框架。
减少使用DashMap，考虑能否使用FxHashMap+channel来进行代替。
减少使用全局变量。
使用channel交换数据。不要通过共享内存来通信。
一般使用普通锁 Mutex，除非很清楚用读写锁RwLock可以提升性能，读写锁因为自身消耗比较高，只有读特别慢，比如有网络请求等场景才需要读写锁。日常很多场景也要尽量规避锁的使用。

## map

* 并发使用

并发的时候可以考虑用dashmap替换hashmap。

* 哈希算法

使用的时候必须使用rustc-hash或fxhash 代替标准库的HashMap或 HashSet 或 dashmap 的哈希算法` static TARGET_NOTIFIERS: Lazy<DashMap<String, Arc<Notify>, FxBuildHasher>> = Lazy::new(|| DashMap::with_hasher(FxBuildHasher));`

* entry的使用

不要写hashmap.entry(key).or_insert(default);要用or_insert_with: `hashmap.entry(key).or_insert_with(||default);`如果使用or_insert，不管map之中是否有这个key，defalut这个都会构造和传递一次，性能损耗比较大，而or_insert_with只是传递一个闭包，不一定真正执行。

* 死锁

DashMap的所有方法都有死锁风险，获取entry的时候都要考虑锁作用范围，不要提前持有锁，用完就需要马上释放。

* 性能

想清楚每一个操作背后所调用的底层指令，比如一个常见的性能浪费：
`if map.contains(some_key) && map.get(some_key).unwrap().can_be_removed()
	map.remove(some_key)`
这里contains/get/remove都调用了一次map的查找some_key的工作，是显然重复的；
可以写成
 `  if let Entry::Occupied(x) = map.entry(some_key)
     if x.get().can_be_removed()
       x.remove()`
如此仅在entry这一个操作调用了查找工作，可以降低整体常数



## Channel

* 慎用unbounded Channel

使用unbounded必须有注释，解释为什么不会oom；
bounded_channel要定义好长度，并且要有阻塞报警代码；
预估业务逻辑上未消费数量在100以内，当到达10000，要打印包含panic字符的日志。
warn!(limit=300;"panic channel长度异常:{}", sender_or_receiver.len());

* 初始化

比较好的方式是在函数内部完成，没有全局变量，示例如下：

`let (sender, receiver) = crossbeam::channel::bounded(10000);`

启动新线程处理receiver
sender可以随着参数分发到各个函数，进行sender.send()操作,如果是分发到多个线程，sender可以clone

全局变量的方式，示例如下：

```rust
//这段代码摘抄自信号的共享内存写入和zmq网络发送。
struct ShmConf {
    pub sender: Sender<Vec<u8>>,
}
static g_shmConf: Lazy<ShmConf> = Lazy::new(|| {
    let (sender, receiver) = crossbeam::channel::bounded(1000);
    let res = ShmConf {
        sender,
    };
    std::thread::Builder::new()
        .name(format!("shm pushing"))
        .spawn(move || -> Result<()> {
            while let Ok(msg) = receiver.recv() {
              //把信号进行共享内存写入，zmq网络发送等
            }
            Ok(())
        })
        .unwrap();

    res
});
impl ShmConf {
    ///全局调用g_shmConf.send(&msg)?就可以在任意函数内发送数据
    pub fn send(&self, msg: Vec<u8>) -> Result<()> {
        if self.sender.is_full() {
            //这一段代码很有用，channel的send都做是否满了的检查，可以检查性能问题
            info!(limit=300;"shm sender is full");
        }
        self.sender.send(msg)?;
        Ok(())
    }
}
```

* Channel的销毁

在线任务场景，通常channel是不需要销毁的，也就是sender一直存在，receiver一直接收数据。

如果是离线任务场景，receiver需要知道什么时候结束。这时候需要把所有的sender进行销毁操作，可能要在sender发送完毕之后，对应的显示操作：

`std::mem::drop(sender);`

只要receiver对应的所有sender的clone都是销毁了的，那么receiver的recv就会结束，也就是while let Ok(data) = receiver.recv会结束。

* 一些有关Channel的设计细节

1. 在负载足够的情况下，可将多个channel reader合并到同一线程，降低并发线程数：

```rust
loop
    let mut recved_something = false
    if let Ok(x) = reader1.try_recv()
	recved_something = true
    if let Ok(x) = reader2.try_recv()
	recved_something = true		...
    if !recved_something
	sleep 1µs
```

2. 在延时敏感的场景，使用 try_recv() + sleep 1µs，代替会存在block可能的recv()，稍稍提高CPU占用率，大幅降低延迟；
3. 每个高性能线程补充必要的延时统计模块，每隔一段时间输出 平均延时&最大延时&个数，不定期review log，看是否存在异常延时情况。其中需要摸清楚每个延时统计的具体含义，比如某些跨机器转发行情，用本机-上游的ts_nanos，可能有机器间的误差，一般在1～2ms内。

## 数据结构选择

```
Vec：连续内存存放，可以随机访问，尾部添加删除复杂度O(1)，空间不足复制一次。不要在头部或者中间添加数据。

VecDeque：环状队列，头尾添加删除复杂度O(1)，能用Vec就不要用VecDeque。
    场景示例：维护过去一段时间的交易量
    
LinkedList:  链表，99%场景用不上。读取O(n)，头尾操作复杂度O(1)，其他位置要先顺序检索到数据O(n)，内存不连续，实际开销比较大。

BTreeMap，有序Map，使用效果近似平衡二叉树（红黑树，AVL等），BTreeMap存储有序，利用CpuCache加速读取，理论复杂度比平衡二叉树高，但是实际效果很好。 
    B-Tree核心点为分成有序数据块，数据块内无序，数据块内每次读取要线性查找，但是内存连续，所以cache命中率高，查找速度快。
    AVL等平衡二叉树数据节点分散，维护成本高，内存不连续。
    场景示例：维护订单簿

BTreeSet，没有value的BTreeMap

HashSet，hash表，实现方式有多重，散列等。先把无限的key映射到有限的空间中，冲突之后排队。线性探测等效率高，跟CpuCache相关。 （实际业务用FxHashMap和FxHashSet，速度更快）

BinaryHeap：堆，logn复杂度的插入，可以取出最大值。（优先队列场景）
```

## 线程池

```toml
# 阻塞队列
crossbeam = "0.8.0"
```

```rust
use std::sync::atomic::{AtomicUsize, Ordering};
use std::sync::{Arc, Mutex};

trait FnBox {
    fn call_box(self: Box<Self>);
}

impl<F: FnOnce()> FnBox for F {
    fn call_box(self: Box<F>) {
        (*self)()
    }
}

type Thunk<'a> = Box<dyn FnBox + Send + 'a>;

pub struct ThreadPool {
    sender: crossbeam::channel::Sender<Thunk<'static>>,
    active_count: Arc<AtomicUsize>,
    size: usize,
}
impl ThreadPool {
    pub fn new(size: usize, name: &str) -> ThreadPool {
        let active_count = Arc::new(AtomicUsize::new(0));
        let (sender, receiver) = crossbeam::channel::unbounded::<Thunk<'static>>();
        for i in 1..=size {
            let receiver = receiver.clone();
            let active_count = active_count.clone();
            std::thread::Builder::new()
                .name(format!("threadpool-{}-{}", name, i))
                .spawn(move || {
                    while let Ok(f) = receiver.recv() {
                        active_count.fetch_add(1, Ordering::SeqCst);
                        f.call_box();
                        active_count.fetch_sub(1, Ordering::SeqCst);
                    }
                })
                .unwrap();
        }
        ThreadPool {
            sender,
            active_count,
            size,
        }
    }

    pub fn execute<F>(&self, job: F)
        where
            F: FnOnce() + Send + 'static,
    {
        self.sender
            .send(Box::new(job))
            .unwrap()
    }

    pub fn active_count(&self) -> usize {
        self.active_count.load(Ordering::SeqCst)
    }

    pub fn queued_count(&self) -> usize {
        self.sender.len()
    }

    pub fn max_count(&self) -> usize {
        self.size
    }

    pub fn join(&self) {
        loop {
            if self.sender.is_empty() {
                break;
            }
            std::thread::sleep(std::time::Duration::from_millis(50))
        }
    }
}
impl Clone for ThreadPool {
    fn clone(&self) -> Self {
        ThreadPool {
            sender: self.sender.clone(),
            active_count: Arc::clone(&self.active_count),
            size: self.size
        }
    }
}

```

* 使用

```rust
use alpha_common::threadpool::ThreadPool;

static THREAD_POOL: Lazy<ThreadPool> = Lazy::new(|| ThreadPool::new(10, "core"));

pub fn pool() -> &'static ThreadPool {
    &THREAD_POOL
}

pub fn do_something() {
  alpha_service::online::utils::core::pool().execute(move|| {
    let _ = builder.create();
  });
}

```

